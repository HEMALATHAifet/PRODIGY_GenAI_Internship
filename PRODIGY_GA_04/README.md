# Task-04: Image-to-Image Translation with cGAN

> Implement an image-to-image translation model using a conditional generative adversarial network (cGAN) called **Pix2Pix**.

---

## ğŸ” Domain

**Computer Vision** â€“ specifically, Image-to-Image Translation using Generative Adversarial Networks (GANs).

---

## ğŸ¯ What is Image-to-Image Translation?

Image-to-image translation is a task in computer vision where an input image is transformed into a corresponding output image. The transformation depends on the task â€” such as converting:

- Sketches â†’ Realistic images
- Daytime photos â†’ Nighttime photos
- Grayscale â†’ Color images

In our case: **Edge Sketch â†’ Realistic Face Image**

---

## ğŸ¤– What is cGAN?

A **Conditional GAN (cGAN)** is a type of Generative Adversarial Network where both the **generator** and **discriminator** receive additional **condition information**, such as class labels or input images.

- **Generator (G)** tries to produce realistic images from input conditions (e.g., edge sketches).
- **Discriminator (D)** tries to distinguish between real images and those generated by G, conditioned on the input.

---

## ğŸ–¼ï¸ What is Pix2Pix?

**Pix2Pix** is a type of cGAN architecture designed for image-to-image translation. It consists of:

- A **U-Net based Generator** â€“ for capturing global and local features from the input.
- A **PatchGAN Discriminator** â€“ evaluates the realism of local image patches instead of the whole image.

---

## ğŸ¯ Purpose of This Project

The goal of this project is to:
- Implement a Pix2Pix model using TensorFlow.
- Train it on a dataset containing **edge-to-face** image pairs.
- Provide a Gradio interface for real-time edge-to-face generation.

---

## ğŸ“ Dataset

Dataset used: **Edge2Face**

- Each training image is a side-by-side (512x256) image where:
  - Left side: Edge sketch
  - Right side: Corresponding face

Folder structure:

```

edge2face/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ img1.png
â”‚   â”œâ”€â”€ img2.png
â”‚   â””â”€â”€ ...

````

---

## ğŸ“œ Code Explanation

### âœ… Preprocessing
- Load `.png` image pairs.
- Split image into input (edges) and target (faces).
- Resize to 256x256 and normalize to [-1, 1].

### âœ… Model
- `pix2pix.unet_generator()` for Generator.
- `pix2pix.discriminator()` for Discriminator.
- Loss functions: Binary Crossentropy + L1 Loss (for generator).

### âœ… Training
- Run training loop for `EPOCHS` (default: 3 for demo).
- Save intermediate results for visualization (optional).

### âœ… Gradio App
- Upload an edge image (256x256).
- Generator predicts realistic face.
- Result shown directly in the browser.

---

## ğŸš€ How to Run

```bash
# Upload edge2face.zip in Google Colab
# Run the notebook

# Start the app
demo.launch()
````

---

## ğŸ”® Future Enhancements

* ğŸ” **Train for more epochs**: Improve image quality by increasing `EPOCHS`.
* ğŸ’¾ **Model checkpointing**: Save and load trained models for reuse.
* ğŸ¨ **Add new domains**: Apply Pix2Pix to other tasks like:

  * Maps â†’ Satellite images
  * BW â†’ Color images
* ğŸ§ª **Use Augmentation**: Improve generalization with image augmentation.
* ğŸ“ˆ **Metrics**: Add FID/SSIM/PSNR to measure performance.

---

## ğŸ“š References

1. [Pix2Pix Paper](https://arxiv.org/abs/1611.07004)
2. [TensorFlow Pix2Pix Tutorial](https://www.tensorflow.org/tutorials/generative/pix2pix)
3. [GitHub - TensorFlow Examples](https://github.com/tensorflow/examples)

---

